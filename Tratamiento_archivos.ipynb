{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtener hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "# Obtenemos la marca de tiempo actual\n",
    "hoy = str(int(time.time()))\n",
    "\n",
    "# Convertimos la marca de tiempo a un entero y luego a una fecha\n",
    "fecha = datetime.fromtimestamp(int(hoy))\n",
    "fecha.year\n",
    "fecha.month\n",
    "fecha.day\n",
    "\n",
    "# Formateamos la fecha en el formato \"Año-Mes-Día\"\n",
    "formato_fecha = fecha.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(formato_fecha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formateo de hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una fecha específica: año, mes, día, hora, minuto, segundo\n",
    "mi_fecha = datetime(2023, 5, 17, 15, 30, 0)\n",
    "\n",
    "# Formatear la fecha en el formato \"Año-Mes-Día\"\n",
    "formato_fecha = mi_fecha.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(formato_fecha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenar dos archivos json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Cargar los dos archivos JSON\n",
    "with open(\"./valores_diarios/1950_1_1.json\", \"r\") as file1, open(\"./valores_diarios/1950_1_16.json\", \"r\") as file2:\n",
    "    data1 = json.load(file1)  # Cargar JSON 1\n",
    "    data2 = json.load(file2)  # Cargar JSON 2\n",
    "\n",
    "# Concatenar las listas\n",
    "combined_data = data1 + data2\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo\n",
    "with open(\"./valores_diarios/data.json\", \"w\") as output_file:\n",
    "    json.dump(combined_data, output_file, indent=4)\n",
    "\n",
    "print(\"Archivos concatenados y guardados en 'combined.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converitr json a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "with open(\"./valores_diarios/data.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)  # Cargar la lista de diccionarios\n",
    "    \n",
    "# Detectar todas las claves únicas\n",
    "fieldnames = set()\n",
    "for row in data:\n",
    "    fieldnames.update(row.keys())\n",
    "fieldnames = list(fieldnames)  # Convertir a lista\n",
    "print(fieldnames)\n",
    "\n",
    "# Convertir a CSV\n",
    "with open(\"./valores_diarios/data.csv\", \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()  # Escribir encabezados\n",
    "    writer.writerows(data)  # Escribir filas\n",
    "print(\"Archivo CSV generado como 'data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consolido archivos en dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data1.csv'\n",
    "data2csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data2.csv'\n",
    "datasetcsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset.csv'\n",
    "dataset1= pd.read_csv(data1csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset2 = pd.read_csv(data2csv, delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los DataFrames (uno debajo del otro)\n",
    "dataset = pd.concat([dataset1, dataset2], ignore_index=True)\n",
    "dataset = dataset.reset_index()\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(datasetcsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data1.csv'\n",
    "data2csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data2.csv'\n",
    "data3csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data3.csv'\n",
    "data4csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data4.csv'\n",
    "data5csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data5.csv'\n",
    "data6csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data6.csv'\n",
    "datasetcsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset.csv'\n",
    "datasetfiltrocsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro.csv'\n",
    "dataset1 = pd.read_csv(data1csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset2 = pd.read_csv(data2csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset3 = pd.read_csv(data3csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset4 = pd.read_csv(data4csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset5 = pd.read_csv(data5csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset6 = pd.read_csv(data6csv, delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los DataFrames (uno debajo del otro)\n",
    "dataset = pd.concat([dataset1, dataset2, dataset3, dataset4, dataset5, dataset6], ignore_index=True)\n",
    "dataset = dataset.reset_index()\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(datasetcsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro por provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias = dataset['provincia'].unique().tolist()\n",
    "display(provincias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias_filtradas = [\"TARRAGONA\", \"GIRONA\", \"BARCELONA\", \"ALICANTE\", \"VALENCIA\", \"CASTELLON\", \"BALEARES\"]\n",
    "dataset_filtro = dataset[dataset[\"provincia\"].isin(provincias_filtradas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtro.to_csv(datasetfiltrocsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uno datasets 7-12 con datasetfiltro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data7csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data7.csv'\n",
    "data8csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data8.csv'\n",
    "data9csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data9.csv'\n",
    "data10csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data10.csv'\n",
    "data11csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data11.csv'\n",
    "data12csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data12.csv'\n",
    "datasetcsv0 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset.csv'\n",
    "datasetfiltrocsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro.csv'\n",
    "dataset7 = pd.read_csv(data7csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset8 = pd.read_csv(data8csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset9 = pd.read_csv(data9csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset10 = pd.read_csv(data10csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset11 = pd.read_csv(data11csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset12 = pd.read_csv(data12csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "datasetfiltro = pd.read_csv(datasetfiltrocsv, delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los DataFrames (uno debajo del otro)\n",
    "dataset12 = pd.concat([datasetfiltro, dataset7, dataset8, dataset9, dataset10, dataset11, dataset12], ignore_index=True)\n",
    "dataset12 = dataset12.reset_index()\n",
    "display(dataset12.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetcsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset12.to_csv(datasetcsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtro por provincias y guardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias = dataset12['provincia'].unique().tolist()\n",
    "display(provincias)\n",
    "provincias_filtradas = [\"TARRAGONA\", \"GIRONA\", \"BARCELONA\", \"ALICANTE\", \"VALENCIA\", \"CASTELLON\", \"BALEARES\"]\n",
    "dataset_filtro = dataset12[dataset12[\"provincia\"].isin(provincias_filtradas)]\n",
    "dataset_filtro.to_csv(datasetfiltrocsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtener los indices de las estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_tarragona = dataset_filtro[\"provincia\"].isin([\"TARRAGONA\"])\n",
    "display(filtro_tarragona)\n",
    "indices_tarragona = dataset_filtro['indicativo'].unique().tolist()\n",
    "display(indices_tarragona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_tarragona = dataset_filtro[dataset_filtro[\"provincia\"].isin(['TARRAGONA'])]\n",
    "display(data_tarragona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarragona = data_tarragona['indicativo'].unique().tolist()\n",
    "display(tarragona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consolido dataset 13-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data13csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data13.csv'\n",
    "data14csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data14.csv'\n",
    "data15csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data15.csv'\n",
    "data16csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data16.csv'\n",
    "data17csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data17.csv'\n",
    "data18csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data18.csv'\n",
    "data19csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data19.csv'\n",
    "datasetcsv1 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset1.csv'\n",
    "datasetfiltrocsv1 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro1.csv'\n",
    "datasetfiltrocsv2 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro2.csv'\n",
    "dataset13 = pd.read_csv(data13csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset14 = pd.read_csv(data14csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset15 = pd.read_csv(data15csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset16 = pd.read_csv(data16csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset17 = pd.read_csv(data17csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset18 = pd.read_csv(data18csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset19 = pd.read_csv(data19csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "datasetfiltro1 = pd.read_csv(datasetfiltrocsv1, delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los DataFrames (uno debajo del otro)\n",
    "datasetconcat = pd.concat([datasetfiltro1, dataset13, dataset14, dataset15, dataset16, dataset17, dataset18, dataset19], ignore_index=True)\n",
    "datasetconcat = datasetconcat.reset_index(drop=True)\n",
    "display(datasetconcat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetcsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset2.csv'\n",
    "datasetconcat.to_csv(datasetcsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias = datasetconcat['provincia'].unique().tolist()\n",
    "display(provincias)\n",
    "provincias_filtradas = [\"TARRAGONA\", \"GIRONA\", \"BARCELONA\", \"ALICANTE\", \"VALENCIA\", \"CASTELLON\", \"BALEARES\"]\n",
    "dataset_filtro2 = datasetconcat[datasetconcat[\"provincia\"].isin(provincias_filtradas)]\n",
    "dataset_filtro2.to_csv(datasetfiltrocsv2, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtro2 = dataset_filtro2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenar de 20 al 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data20csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data20.csv'\n",
    "data21csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data21.csv'\n",
    "data22csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data22.csv'\n",
    "data23csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data23.csv'\n",
    "data24csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data24.csv'\n",
    "data25csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data25.csv'\n",
    "data26csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data26.csv'\n",
    "datasetcsv2 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset2.csv'\n",
    "datasetfiltrocsv2 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro2.csv'\n",
    "datasetfiltrocsv3 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro3.csv'\n",
    "dataset20 = pd.read_csv(data20csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset21 = pd.read_csv(data21csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset22 = pd.read_csv(data22csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset23 = pd.read_csv(data23csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset24 = pd.read_csv(data24csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset25 = pd.read_csv(data25csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset26 = pd.read_csv(data26csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "datasetfiltro2 = pd.read_csv(datasetfiltrocsv2, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Concatenar los DataFrames (uno debajo del otro)\n",
    "datasetconcat = pd.concat([datasetfiltro2, dataset20, dataset21, dataset22, dataset23, dataset24, dataset25, dataset26], ignore_index=True)\n",
    "datasetconcat = datasetconcat.reset_index(drop=True)\n",
    "display(datasetconcat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetcsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset3.csv'\n",
    "datasetconcat.to_csv(datasetcsv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias = datasetconcat['provincia'].unique().tolist()\n",
    "display(provincias)\n",
    "provincias_filtradas = [\"TARRAGONA\", \"GIRONA\", \"BARCELONA\", \"ALICANTE\", \"VALENCIA\", \"CASTELLON\", \"BALEARES\"]\n",
    "dataset_filtro3 = datasetconcat[datasetconcat[\"provincia\"].isin(provincias_filtradas)]\n",
    "dataset_filtro3.to_csv(datasetfiltrocsv3, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data27csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data27.csv'\n",
    "data28csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data28.csv'\n",
    "data29csv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data29.csv'\n",
    "\n",
    "datasetcsv2 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset3.csv'\n",
    "datasetfiltrocsv3 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro3.csv'\n",
    "datasetfiltrocsv4 = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_filtro4.csv'\n",
    "\n",
    "dataset27 = pd.read_csv(data27csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset28 = pd.read_csv(data28csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "dataset29 = pd.read_csv(data29csv, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "datasetfiltro3 = pd.read_csv(datasetfiltrocsv3, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Concatenar los DataFrames (uno debajo del otro)\n",
    "datasetconcat = pd.concat([datasetfiltro3, dataset27, dataset28, dataset29], ignore_index=True)\n",
    "datasetconcat = datasetconcat.reset_index(drop=True)\n",
    "display(datasetconcat.head())\n",
    "\n",
    "datasetcsv = '/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset4.csv'\n",
    "datasetconcat.to_csv(datasetcsv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "provincias = datasetconcat['provincia'].unique().tolist()\n",
    "display(provincias)\n",
    "provincias_filtradas = [\"TARRAGONA\", \"GIRONA\", \"BARCELONA\", \"ALICANTE\", \"VALENCIA\", \"CASTELLON\", \"BALEARES\"]\n",
    "dataset_filtro4 = datasetconcat[datasetconcat[\"provincia\"].isin(provincias_filtradas)]\n",
    "dataset_filtro4.to_csv(datasetfiltrocsv4, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* me falta el año 2017, así que voy a generar el csv a partir del json y después lo añadiré al dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Cargar el CSV original y obtener la estructura de columnas\n",
    "df_original = pd.read_csv(\"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data/data01.csv\")\n",
    "columnas = df_original.columns\n",
    "\n",
    "# Ruta de la carpeta donde están los archivos JSON\n",
    "carpeta = \"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/decada2010/2017\"\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Buscar todos los archivos JSON en la carpeta\n",
    "for archivo in glob.glob(os.path.join(carpeta, \"*.json\")):\n",
    "    try:\n",
    "        # Cargar cada archivo JSON\n",
    "        df = pd.read_json(archivo)\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {archivo}: {e}\")\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_final = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_final = df_final[columnas]\n",
    "\n",
    "df_final[\"fecha\"] = pd.to_datetime(df_final[\"fecha\"])\n",
    "df_final.sort_values(by=\"fecha\", ascending=True, inplace=True)\n",
    "# Guardar como CSV\n",
    "df_final.to_csv(\"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data/data30.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Archivo CSV combinado guardado exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Carpeta donde están los archivos CSV\n",
    "carpeta = \"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data\"\n",
    "\n",
    "# Obtener y ordenar la lista de archivos CSV en orden ascendente\n",
    "archivos = sorted([f for f in os.listdir(carpeta) if f.endswith(\".csv\")])\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Leer y concatenar archivos en orden\n",
    "for archivo in archivos:\n",
    "    ruta_completa = os.path.join(carpeta, archivo)\n",
    "    df = pd.read_csv(ruta_completa)  # Leer CSV\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_final = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Guardar en un nuevo archivo CSV\n",
    "df_final.to_csv(\"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data_completo.csv\", index=False)\n",
    "\n",
    "print(\"Proceso completado. Archivo guardado como 'archivo_concatenado.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro Asturias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacsv = \"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/data_completo.csv\"\n",
    "datacsv_asturias = \"/home/miguel/Documentos/MASTER_BIG_DATA/14_TFM/valores_diarios/dataset_asturias.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(datacsv, delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias_filtradas = [\"ASTURIAS\"]\n",
    "dataset_asturias = dataset[dataset[\"provincia\"].isin(provincias_filtradas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_asturias.to_csv(datacsv_asturias, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_asturias= pd.read_csv(datacsv_asturias, delimiter=\",\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER_BIG_DATA-UsmuGMTr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
